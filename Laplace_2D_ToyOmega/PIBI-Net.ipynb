{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63082b0a",
   "metadata": {},
   "source": [
    "# Physics-Informed Integral Network for Laplace Equation\n",
    "(Please reference to our paper **Physics-Informed Boundary Integral Networks (PIBI-Nets): a Data-Driven Approach for Solving Partial Differential Equations**.)\n",
    "\n",
    "---\n",
    "## Problem setup\n",
    " \n",
    "### Laplace equation \n",
    "$$ \\Delta u(x) := \\frac{\\partial^2 u}{\\partial x_1^2} + \\frac{\\partial^2 u}{\\partial x_2^2} = 0 $$\n",
    " \n",
    "$$x:=(x_1, x_2)\\, \\in \\Omega \\subseteq \\mathbb{R}^2$$\n",
    " \n",
    "For sake of simplicity, we choose $\\Omega$ to be a circle.\n",
    " \n",
    "### Single and double layer potential\n",
    "For a point $x\\in\\Omega$ inside the domain we have \n",
    "$$u(x) = \\left( \\int_{\\partial \\Omega} G(x,y)\\cdot \\frac{\\partial g}{\\partial n}(y) dS_y \\right) - \\left(\\int_{\\partial \\Omega} \\frac{\\partial G}{\\partial n}(x,y)\\cdot g(y) dS_y \\right).$$\n",
    "But for a boundary point $x\\in\\Gamma:=\\partial\\Omega$ we have get a jump\n",
    "$$\n",
    "u(x) = \\left( \\int_{\\partial \\Omega} G(x,y)\\cdot \\frac{\\partial g}{\\partial n}(y) dS_y \\right) - \\left(\\int_{\\partial \\Omega} \\frac{\\partial G}{\\partial n}(x,y)\\cdot g(y) dS_y \\right) +\n",
    "\\frac{1}{2}g(x).\n",
    "$$\n",
    " \n",
    " \n",
    " \n",
    "### Uniformal sampled datapoints based on FD solution given by Dirichlet boundary conditions\n",
    "Let ${\\large\\{}u_i(x){\\large\\}}_{i=0}^{i=N}$ be the measurements constructed by a finite difference solution of the Laplace equation based on Dirichlet boundary conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922d32f",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e8cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm  # colormaps\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['text.usetex'] = True\n",
    "# font properties for plot titles\n",
    "font_axis = FontProperties()\n",
    "font_axis.set_family('serif')\n",
    "font_axis.set_name('Times New Roman')\n",
    "font_axis.set_size(115)  # Set the font size to match LaTeX, e.g., 12pt\n",
    "# font properties for 3d plot titles\n",
    "font_axis_3d = FontProperties()\n",
    "font_axis_3d.set_family('serif')\n",
    "font_axis_3d.set_name('Times New Roman')\n",
    "font_axis_3d.set_size(90)  # Set the font size to match LaTeX, e.g., 12pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c757b",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eeb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from CSV file into a pandas DataFrame and save as Torch tensor\n",
    "def read_data(csv_file):\n",
    "    \"\"\"\n",
    "    read csv file and store data in x_data, u_data\n",
    "    \n",
    "    Args:\n",
    "    - csv_file\n",
    "    \n",
    "    Returns:\n",
    "    - x_data: tensor of shape (N,2) containing N positions x=(x1,x2)\n",
    "    - u_data: tensor of shape (N,1) containing u values to corresponding x\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # read data from CSV file into a pandas DataFrame and save as Torch tensor\n",
    "    data_pd = pd.read_csv(csv_file)\n",
    "    # convert pandas DataFrame to PyTorch tensor\n",
    "    data_tensor = torch.tensor(data_pd.values, dtype=torch.float32)  # x1, x2, u\n",
    "    x_data = data_tensor[:, 0:2]  # x1, x2, (N,2)\n",
    "    u_data = data_tensor[:, 2].view(-1, 1)  # u, (N,1)\n",
    "    return x_data, u_data\n",
    "\n",
    "\n",
    "x_data, u_data = read_data('dataset_laplace.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d390980",
   "metadata": {},
   "source": [
    "## Physics initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbcb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer normal directional derivative on boundary of Omega (as a circle)\n",
    "def outer_normal(x, radius, middle):\n",
    "    \"\"\"\n",
    "    computes outer normal vector normals that is orthogonal to surface of Omega\n",
    "    \n",
    "    Args:\n",
    "    - x: tensor of shape (N,2) containing N positions (x1, x2) on boundary of Omega\n",
    "    \n",
    "    Returns:\n",
    "    - normals: tensor of shape (N,2) containing the outer normal vector on boundary of Omega at each position in x\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    N = x.shape[0]  # number of points\n",
    "    xc = x - middle  # cetered\n",
    "    normals = xc / radius\n",
    "\n",
    "    return normals\n",
    "\n",
    "\n",
    "# Physics initialisation for 2D Laplace equation Î”ð‘¢(ð‘¥):= âˆ‚^2(ð‘¢)/âˆ‚(ð‘¥_1)^2 + âˆ‚^2(ð‘¢)/âˆ‚(ð‘¥_2)^2 = 0\n",
    "# fundamental solution of Laplace equation in 2D\n",
    "def fundamental_solution(x, y):\n",
    "    \"\"\"\n",
    "    computes the fundamental solution of the Laplace equation in 2D at N positions in  \n",
    "    two points x and y in R^2, given by\n",
    "    Phi_0(x, y) = -1/(2Ï€) * log(||x - y||)\n",
    "    \n",
    "    Args:\n",
    "    - x: torch.tensor of position x on Domain Omega, shape (N,2)\n",
    "    - y: torch.tensor of position y on Domain Omega, shape (N,2) \n",
    "    \n",
    "    Returns:\n",
    "    - Phi_0: torch.tensor of shape (N,1), value of Laplace fundamental solution over x and y\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    distance = torch.norm(x - y, p=2, dim=1).view(-1, 1) + 1e-8\n",
    "    # check if distance is >0, otherwise raise an error because ln(0) = -infinity\n",
    "    # if (distance == 0).any():\n",
    "    #     raise ValueError(\"Points must be distinct\")  # produce error\n",
    "\n",
    "    Phi_0 = -1 / (2 * np.pi) * torch.log(distance)\n",
    "    return Phi_0\n",
    "\n",
    "\n",
    "# gradient of fundamental solution with respect to y\n",
    "# grad Phi_0(x,y) = 1/(2Ï€) * (x - y)/||x - y||Â²\n",
    "def gradient_fundamental(x, y):\n",
    "    \"\"\"\n",
    "    computes the gradient *with respect to x* of the Laplace fundamental solution in 2D at N positions x and y, \n",
    "    given by âˆ‡y Phi_0(x,y) = - 1/(2Ï€) * (x - y)/||x - y||Â²\n",
    "    \n",
    "    Args:\n",
    "    - x: torch.tensor of position x on Domain Omega, shape (N,2)\n",
    "    - y: torch.tensor of position y on Domain Omega, shape (N,2) \n",
    "    \n",
    "    Returns:\n",
    "    - grad_Phi_0: torch.tensor of shape (N,2), gradient of Laplace fundamental solution over x and y\n",
    "    \n",
    "    \"\"\"\n",
    "    distance = torch.norm(x - y + 1e-8, p=2, dim=1).view(-1, 1)\n",
    "\n",
    "    # check if distance is >0, otherwise raise an error\n",
    "    # if (distance == 0).any():\n",
    "    #     raise ValueError(\"Points must be distinct\")  # produce error\n",
    "    grad_Phi_0 = (1 / (2 * np.pi)) * ((x - y) / distance ** 2)\n",
    "    return grad_Phi_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c6609",
   "metadata": {},
   "source": [
    "## Collocation and integration points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocation_integration_points(n, radius, middle):\n",
    "    # add random shift\n",
    "    angle = (2 * np.pi * torch.rand(1)).item()\n",
    "\n",
    "    # define angles\n",
    "    n = n + 1\n",
    "    theta = np.linspace(0, 2 * np.pi, n) + angle\n",
    "    theta = theta[1::]  # to remove one double angle at 0 and 2*pi\n",
    "    # split theta into two sets\n",
    "    theta_coll = theta[::2]  # select every second point\n",
    "    theta_int = theta[1::2]  # select every other points\n",
    "\n",
    "    # define collocation points\n",
    "    x1_coll = middle[:, 0] + radius * np.cos(theta_coll).reshape(int(n / 2), 1)\n",
    "    x2_coll = middle[:, 1] + radius * np.sin(theta_coll).reshape(int(n / 2), 1)\n",
    "    x_collocation = np.concatenate((x1_coll, x2_coll), axis=1)\n",
    "    x_collocation = torch.tensor(x_collocation, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "    # define integration points\n",
    "    x1_int = middle[:, 0] + radius * np.cos(theta_int).reshape(int(n / 2), 1)\n",
    "    x2_int = middle[:, 1] + radius * np.sin(theta_int).reshape(int(n / 2), 1)\n",
    "    x_integration = np.concatenate((x1_int, x2_int), axis=1)\n",
    "    x_integration = torch.tensor(x_integration, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "    return x_collocation, x_integration  # each of shape (n/2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "radius = 1.5\n",
    "middle = torch.tensor((0, 0)).view(1, 2)\n",
    "x_collocation, x_integration = collocation_integration_points(n, radius, middle)\n",
    "x_coll_np = x_collocation.detach().numpy()\n",
    "x_int_np = x_integration.detach().numpy()\n",
    "\n",
    "# plot collocation and integration points\n",
    "plt.scatter(x_coll_np[:, 0], x_coll_np[:, 1], color='red', label='Collocation Points')\n",
    "plt.scatter(x_int_np[:, 0], x_int_np[:, 1], color='blue', label='Integration Points')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87aff34",
   "metadata": {},
   "source": [
    "## FD mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd83155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from CSV file into a pandas DataFrame and save as Torch tensor\n",
    "x_num = pd.read_csv('X_mesh.csv')\n",
    "# convert pandas DataFrame to PyTorch tensor\n",
    "x_num = torch.tensor(x_num.values, dtype=torch.float32)  # x1, x2\n",
    "\n",
    "# read data from CSV file into a pandas DataFrame and save as Torch tensor\n",
    "u_num = pd.read_csv('u_num.csv')\n",
    "# convert pandas DataFrame to PyTorch tensor\n",
    "u_num = torch.tensor(u_num.values, dtype=torch.float32)  # u\n",
    "\n",
    "N = u_num.shape\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a5776",
   "metadata": {},
   "source": [
    "## Network setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully-connected neural network setup with PyTorch\n",
    "class FCNN(nn.Module):\n",
    "    n_integration_points = 1_000\n",
    "\n",
    "    def __init__(self, N_input, N_output, N_hidden, N_layers):\n",
    "        \"\"\"\n",
    "        class implementation of a fully-connected neural network with PyTorch given by Args\n",
    "        \n",
    "        Args:\n",
    "        - N_input: integer, number of input dimension, here N_input = 2 given by x=(x1, x2)\n",
    "        - N_output: integer, number of output dimession, here N_output = 1 given by u(x)\n",
    "        - N_hidden: integer, depth of one hidden layer\n",
    "        - N_layers: integer, number of hidden layers in the network\n",
    "        \n",
    "        Methods:\n",
    "        - forward: forward pass of neural network\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        activation = nn.ELU\n",
    "\n",
    "        # input / start layer\n",
    "        self.fc_start = nn.Sequential(*[\n",
    "            nn.Linear(N_input, N_hidden),\n",
    "            activation()\n",
    "        ])\n",
    "        # hidden layers\n",
    "        self.fc_hidden = nn.Sequential(*[\n",
    "            nn.Sequential(*[\n",
    "                nn.Linear(N_hidden, N_hidden),\n",
    "                activation()\n",
    "            ])\n",
    "            for _ in range(N_layers - 1)  # -1 since first layer already defined before for-loop\n",
    "        ])\n",
    "        # output / end layer\n",
    "        self.fc_end = nn.Linear(N_hidden, N_output)\n",
    "\n",
    "        self.x_coll, self.x_int = collocation_integration_points(self.n_integration_points, radius, middle)\n",
    "        self.vmapped_potential = torch.vmap(self.calc_potentials, randomness='same')\n",
    "        self.vmapped_potential_xcol = torch.vmap(self.calc_potentials_xcoll, randomness='same')\n",
    "\n",
    "    def resample(self):\n",
    "        self.x_coll, self.x_int = collocation_integration_points(self.n_integration_points, radius, middle)\n",
    "        self.vmapped_potential = torch.vmap(self.calc_potentials, randomness='same')\n",
    "        self.vmapped_potential_xcol = torch.vmap(self.calc_potentials_xcoll, randomness='same')\n",
    "\n",
    "    def predict_u_inside(self, x):\n",
    "        double_layer, single_layer = self.vmapped_potential(x)\n",
    "        u_int_data = (single_layer.squeeze() - double_layer.squeeze()).view(-1, 1)\n",
    "        return u_int_data\n",
    "\n",
    "    def predict_u_boundary(self, x):\n",
    "        double_layer, single_layer = self.vmapped_potential_xcol(x)\n",
    "        u_int_boundary = (single_layer.squeeze() - double_layer.squeeze()).view(-1, 1)\n",
    "        return u_int_boundary\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward pass through network building blocks given in this class above\n",
    "        \n",
    "        Args:\n",
    "        - x: tensor of shape (N, 2) containing N positions (x1, x2)\n",
    "\n",
    "        Returns:\n",
    "        - u: tensor of shape (N,1) containing the network solution u at position x\n",
    "        \n",
    "        \"\"\"\n",
    "        # forward network\n",
    "        x = self.fc_start(x)  # input layer\n",
    "        x = self.fc_hidden(x)  # hidden layer(s)\n",
    "        u = self.fc_end(x)  # output layer\n",
    "\n",
    "        return u\n",
    "\n",
    "    def calc_potentials(self, x):\n",
    "        \"\"\"\n",
    "        Inner domain points\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # single_layer\n",
    "        # define collocation and integration points\n",
    "        y = self.x_int\n",
    "        # normal vectors\n",
    "        normal_y = outer_normal(y, radius, middle)\n",
    "        # boundary density\n",
    "        g_y = self(y)\n",
    "        G = fundamental_solution(x, y)\n",
    "        grad_ones = torch.ones_like(g_y)\n",
    "        dg_dy = torch.autograd.grad(g_y, y, grad_outputs=grad_ones, create_graph=True)[0]\n",
    "        dg_dn = torch.sum(dg_dy * normal_y, dim=1).view(-1, 1)\n",
    "        single_layer = torch.mean(G * dg_dn)\n",
    "        ################\n",
    "        # double_layer\n",
    "        dG_dy = gradient_fundamental(x, y)\n",
    "        dG_dn = torch.sum(dG_dy * normal_y, dim=1).view(-1, 1)\n",
    "        double_layer = torch.mean(dG_dn * g_y)\n",
    "        return double_layer.squeeze(), single_layer.squeeze()\n",
    "\n",
    "    def calc_potentials_xcoll(self, x):\n",
    "        \"\"\"\n",
    "        for boundary\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        y = self.x_int\n",
    "        g_y = self(y)\n",
    "\n",
    "        G = fundamental_solution(x, y)\n",
    "        grad_ones = torch.ones_like(g_y)\n",
    "        dg_dy = torch.autograd.grad(g_y, y, grad_outputs=grad_ones, create_graph=True)[0]\n",
    "        normal_y = outer_normal(y, radius, middle)\n",
    "        dg_dn = torch.sum(dg_dy * normal_y, dim=1).view(-1, 1)\n",
    "        single_layer = torch.mean(G * dg_dn)\n",
    "        ################\n",
    "        # double_layer\n",
    "        dG_dy = gradient_fundamental(x, y)\n",
    "        dG_dn = torch.sum(dG_dy * normal_y, dim=1).view(-1, 1)\n",
    "        double_layer = torch.mean(dG_dn * g_y) - 0.5 * pibi(x)\n",
    "        return double_layer.squeeze(), single_layer.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_pibi(lr):\n",
    "    # define number of neurons in each layer type\n",
    "    N_input = 2\n",
    "    N_output = 1\n",
    "    N_hidden = 512\n",
    "    N_layers = 3  # number of hidden layers\n",
    "\n",
    "    # define a neural network to train\n",
    "    pibi = FCNN(N_input, N_output, N_hidden, N_layers)\n",
    "\n",
    "    # optimizer\n",
    "    optimiser = torch.optim.Adam(pibi.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, factor=0.5, eps=1e-12, verbose=True)\n",
    "\n",
    "    # loss function\n",
    "    mse_loss = torch.nn.MSELoss()  # Mean squared error\n",
    "\n",
    "    return pibi, optimiser, scheduler, mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516591d",
   "metadata": {},
   "source": [
    "## Train PIBI and visualise trained solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pibi(iterations, lambda_physics_data, lambda_physics_coll, n, pibi, optimiser, scheduler, mse_loss):\n",
    "    # n: number of collocation and integration points\n",
    "    # store loss values\n",
    "    loss_values = []\n",
    "    # x_coll, x_int = collocation_integration_points(n, radius, middle)\n",
    "    # vmapped_potential = torch.vmap(pibi.calc_potentials, randomness='same')\n",
    "    # vmapped_potential_xcol = torch.vmap(pibi.calc_potentials_xcoll, randomness='same')\n",
    "\n",
    "    for epoch in range(iterations):\n",
    "        # Clear gradients before forward and backward pass for each batch to avoid accumulation of gradients\n",
    "        optimiser.zero_grad()\n",
    "        pibi.resample()\n",
    "        x_coll = pibi.x_coll\n",
    "\n",
    "        u_int_data = pibi.predict_u_inside(x_data)\n",
    "        loss_int_data = mse_loss(u_int_data, u_data)\n",
    "\n",
    "        u_int_coll = pibi.predict_u_boundary(x_coll)\n",
    "        loss_int_coll = mse_loss(u_int_coll, torch.zeros_like(u_int_coll))\n",
    "\n",
    "        # backpropagate weighted joint loss, take optimiser step\n",
    "        loss = lambda_physics_data * loss_int_data + lambda_physics_coll * loss_int_coll\n",
    "        loss_values.append(loss.item())  # store loss value for convergence plot\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        # plot result as training progresses on test set\n",
    "        if epoch % 2 == 0:\n",
    "            print('epoch:', epoch, ', data:', loss_int_data.data, ', coll:', loss_int_coll.data)\n",
    "\n",
    "            if epoch == iterations - 1:\n",
    "                # save model\n",
    "                torch.save(pibi.state_dict(), \"pibi_model.pt\")\n",
    "\n",
    "                # solve integral for plot points\n",
    "                _, x_int = collocation_integration_points(n, radius, middle)\n",
    "                u_pibi = pibi.predict_u_inside(x_num)\n",
    "                x1 = (x_num[:, 0]).reshape((101, 101))  # (test_size,test_size)\n",
    "                x2 = (x_num[:, 1]).reshape((101, 101))  # (test_size,test_size)\n",
    "                u_nn = u_pibi.reshape(x1.shape)  # nn output, (test_size,test_size)\n",
    "                u_nn = u_nn.detach()\n",
    "\n",
    "                # evaluation plot in 3D\n",
    "                fig = plt.figure(figsize=(15, 15))\n",
    "                ax = fig.add_subplot(111, projection='3d', computed_zorder=False)\n",
    "                surf = ax.plot_surface(x1, x2, u_nn, cmap=cm.jet, zorder=1, alpha=1)\n",
    "                ax.scatter(x_data[:, 0], x_data[:, 1], u_data, c='black', marker='o', s=10 ** 2, alpha=1, zorder=2)\n",
    "                surf.set_clim(vmin=-1, vmax=1)  # limits to colorbar\n",
    "                # fig.colorbar(surf, shrink=0.45, aspect=10, pad=0.2)\n",
    "                fig.axes[0].tick_params(axis=\"both\", labelsize=20)\n",
    "                # fig.axes[1].tick_params(axis=\"both\", labelsize=45)\n",
    "                # axis ticks\n",
    "                ax.tick_params(axis=\"both\", labelsize=60, pad=20)\n",
    "                major_ticks = [-1, -0.5, 0, 0.5, 1]\n",
    "                ax.set_xticks(major_ticks)\n",
    "                ax.set_yticks(major_ticks)\n",
    "                ax.set_zticks(major_ticks)\n",
    "                # tick colour\n",
    "                ax.tick_params(axis='x', colors='grey')\n",
    "                ax.tick_params(axis='y', colors='grey')\n",
    "                ax.tick_params(axis='z', colors='grey')\n",
    "                # labels\n",
    "                ax.set_xlabel('$x_1$', fontproperties=font_axis_3d, labelpad=55)\n",
    "                ax.set_ylabel('$x_2$', fontproperties=font_axis_3d, labelpad=55)\n",
    "                ax.set_zlabel('$u$', fontproperties=font_axis_3d, labelpad=55)\n",
    "                # plt.title(f\"PIBI-Net at epoch {epoch}\", size=20)\n",
    "                # Save the figure as a JPEG image\n",
    "                plt.savefig('piibi_3d.jpg', dpi=500, format='jpeg', bbox_inches='tight')\n",
    "                plt.show()\n",
    "\n",
    "                # evaluation plot in 2d\n",
    "                fig, ax = plt.subplots(figsize=(15, 15))\n",
    "                img = ax.imshow(u_nn, cmap='jet', origin='lower',\n",
    "                                extent=[torch.min(x1).item(), torch.max(x1).item(),\n",
    "                                        torch.min(x2).item(), torch.max(x2).item()],\n",
    "                                vmin=-1, vmax=1)\n",
    "                ax.scatter(x_data[:, 0], x_data[:, 1], c='black', marker='o', s=10 ** 2, alpha=1, zorder=4)\n",
    "                # fig.colorbar(img, ax=ax, shrink=0.55, aspect=10, pad=0.2)\n",
    "                # tick sizes\n",
    "                fig.axes[0].tick_params(axis=\"both\", labelsize=20)\n",
    "                # fig.axes[1].tick_params(axis=\"both\", labelsize=45)\n",
    "                # axis ticks\n",
    "                ax.tick_params(axis=\"both\", labelsize=70, pad=5)\n",
    "                major_ticks = [-1, -0.5, 0, 0.5, 1]\n",
    "                ax.set_xticks(major_ticks)\n",
    "                ax.set_yticks(major_ticks)\n",
    "                # tick colour\n",
    "                ax.tick_params(axis='x', colors='grey')\n",
    "                ax.tick_params(axis='y', colors='grey')\n",
    "                # labels\n",
    "                ax.set_xlabel('$x_1$', fontproperties=font_axis, labelpad=0)\n",
    "                ax.set_ylabel('$x_2$', fontproperties=font_axis, labelpad=-20)\n",
    "                # plt.title(f\"PIIBI-Net at epoch {epoch} (Top view)\", size=20)\n",
    "                # Save the figure as a JPEG image \n",
    "                plt.savefig('pibi_2d.jpg', dpi=500, format='jpeg', bbox_inches='tight')\n",
    "                plt.show()\n",
    "\n",
    "                # absolute error plot\n",
    "                u_num_matrix = u_num.reshape(u_nn.shape)\n",
    "                u_error = torch.abs(u_nn - u_num_matrix)\n",
    "                fig, ax = plt.subplots(figsize=(15, 15))\n",
    "                img = ax.imshow(u_error, cmap='jet_r', origin='lower',\n",
    "                                extent=[torch.min(x1).item(), torch.max(x1).item(),\n",
    "                                        torch.min(x2).item(), torch.max(x2).item()],\n",
    "                                vmin=0, vmax=0.7)\n",
    "                ax.scatter(x_data[:, 0], x_data[:, 1], c='black', marker='o', s=10 ** 2, alpha=1, zorder=4)\n",
    "                # fig.colorbar(img, ax=ax, shrink=0.55, aspect=10, pad=0.2)\n",
    "                # tick sizes\n",
    "                fig.axes[0].tick_params(axis=\"both\", labelsize=20)\n",
    "                # fig.axes[1].tick_params(axis=\"both\", labelsize=45)\n",
    "                # axis ticks\n",
    "                ax.tick_params(axis=\"both\", labelsize=70, pad=5)\n",
    "                major_ticks = [-1, -0.5, 0, 0.5, 1]\n",
    "                ax.set_xticks(major_ticks)\n",
    "                ax.set_yticks(major_ticks)\n",
    "                # tick colour\n",
    "                ax.tick_params(axis='x', colors='grey')\n",
    "                ax.tick_params(axis='y', colors='grey')\n",
    "                # labels\n",
    "                ax.set_xlabel('$x_1$', fontproperties=font_axis, labelpad=0)\n",
    "                ax.set_ylabel('$x_2$', fontproperties=font_axis, labelpad=-20)\n",
    "                # plt.title('Absolute error (Top View)', size=20)\n",
    "                plt.savefig('pibi_error.jpg', dpi=500, format='jpeg', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                u_vec = u_error.reshape(N, 1)\n",
    "                print('min', torch.min(u_vec), 'max', torch.max(u_vec), 'mean', torch.mean(u_vec), 'std',\n",
    "                      torch.std(u_vec))\n",
    "\n",
    "    return loss_values, pibi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pibi initialisation\n",
    "lr = 1e-3  # learning rate\n",
    "pibi, optimiser, scheduler, mse_loss = initialise_pibi(lr)\n",
    "\n",
    "iterations = 31  # 5_000\n",
    "lambda_physics_data = 1\n",
    "lambda_physics_coll = 1e-6  # weighting of collocation loss\n",
    "n = 1000  # number of collocation points\n",
    "radius = 1.5\n",
    "middle = torch.tensor((0, 0)).view(1, 2)\n",
    "loss_values, pibi = train_pibi(iterations, lambda_physics_data, lambda_physics_coll, n, pibi, optimiser, scheduler,\n",
    "                               mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d9f61",
   "metadata": {},
   "source": [
    "## Visualize convergence of loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b56bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1, iterations + 1))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs, loss_values)\n",
    "ax.set(xlabel='epochs / iterations',\n",
    "       ylabel='loss',\n",
    "       title='Convergence')\n",
    "# plt.savefig('pibi_loss.jpg', dpi=1000, format='jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786834d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970c651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
